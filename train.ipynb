import torch

print(torch.cuda.is_available())  # True
print(torch.cuda.get_device_name(0))  # "NVIDIA GeForce RTX 4070 SUPER"
from datasets import load_dataset

dataset = load_dataset("jeanlee/kmhas_korean_hate_speech")

print(dataset)
print(dataset['train'][0])

# ë‹¤ì¤‘ ë ˆì´ë¸” í•„ë“œ ì§€ì •
label_columns = [
    'hate', 'offensive', 'gender', 'age', 'religion', 'politics',
    'appearance', 'region', 'sexual_orientation'
]


# ë‹¤ì¤‘ ë ˆì´ë¸” ë²¡í„°ë¡œ ë¬¶ê¸°
def format_labels(example):
    example["labels"] = example["label"]  # ê·¸ëƒ¥ ê·¸ëŒ€ë¡œ ë³µì‚¬
    return example


encoded_dataset = dataset.map(format_labels)

NUM_CLASSES = 9  # hate~sexual_orientation


def to_multihot(example):
    multi_hot = [0] * NUM_CLASSES
    for idx in example["labels"]:
        multi_hot[idx] = 1
    example["labels"] = multi_hot
    return example


encoded_dataset = encoded_dataset.map(to_multihot)

from transformers import AutoTokenizer

model_name = "beomi/KcELECTRA-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)


def tokenize_function(example):
    return tokenizer(
        example["text"],
        padding="max_length",
        truncation=True,
        max_length=128
    )


tokenized_dataset = encoded_dataset.map(tokenize_function, batched=True)

tokenized_dataset = tokenized_dataset.remove_columns(['text', 'label'])
tokenized_dataset.set_format("torch")

print(tokenized_dataset["train"][0])

from transformers import ElectraForSequenceClassification
import torch

model = ElectraForSequenceClassification.from_pretrained(
    "beomi/KcELECTRA-base",
    num_labels=9,
    problem_type="multi_label_classification"
)

model.to("cuda")  # âœ… ìˆ˜ë™ìœ¼ë¡œ GPUì— ì˜¬ë¦¼

import numpy as np
from sklearn.metrics import f1_score, accuracy_score


def compute_metrics(pred):
    logits, labels = pred
    probs = torch.sigmoid(torch.tensor(logits)).numpy()  # í™•ë¥ í™”
    preds = (probs >= 0.5).astype(int)  # 0.5 ê¸°ì¤€ ì´ì§„í™”
    labels = labels.astype(int)

    return {
        'accuracy': accuracy_score(labels, preds),
        'micro_f1': f1_score(labels, preds, average='micro'),
        'macro_f1': f1_score(labels, preds, average='macro')
    }


import transformers

print(transformers.__version__)
# âœ… 4.40.x ì´ìƒì´ë©´ OK

from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    logging_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=32,
    num_train_epochs=3,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="micro_f1",
    save_total_limit=1,
    report_to="none"
)

from transformers import DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors="pt")

# âœ… Trainer ì •ì˜ ì‹œ ì´ê±¸ ì¶”ê°€!
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

import numpy as np
from sklearn.metrics import f1_score, accuracy_score


def compute_metrics(pred):
    logits, labels = pred
    probs = torch.sigmoid(torch.tensor(logits)).numpy()
    preds = (probs >= 0.5).astype(int)
    labels = labels.astype(int)
    return {
        'accuracy': accuracy_score(labels, preds),
        'micro_f1': f1_score(labels, preds, average='micro'),
        'macro_f1': f1_score(labels, preds, average='macro')
    }


def to_multihot(example):
    multi_hot = [0.0] * 9  # floatìœ¼ë¡œ ì´ˆê¸°í™”
    for idx in example["label"]:
        multi_hot[idx] = 1.0
    example["labels"] = multi_hot
    return example


encoded_dataset = dataset.map(to_multihot)

tokenized_dataset = encoded_dataset.map(tokenize_function, batched=True)
tokenized_dataset = tokenized_dataset.remove_columns(['text', 'label'])
tokenized_dataset.set_format("torch")

# í† í¬ë‚˜ì´ì§• ì™„ë£Œ í›„
tokenized_dataset = encoded_dataset.map(tokenize_function, batched=True)


# ğŸ‘‡ ì—¬ê¸°ì„œ float32 ë³€í™˜ ì¶”ê°€!
def cast_label_to_float(example):
    example["labels"] = [float(x) for x in example["labels"]]
    return example


tokenized_dataset = tokenized_dataset.map(cast_label_to_float)

# ê·¸ ë‹¤ìŒ ë‚˜ë¨¸ì§€ ê·¸ëŒ€ë¡œ ìœ ì§€
tokenized_dataset = tokenized_dataset.remove_columns(['text', 'label'])
tokenized_dataset.set_format("torch")


def cast_label_to_float(example):
    example["labels"] = torch.tensor(example["labels"], dtype=torch.float32)
    return example


tokenized_dataset = tokenized_dataset.map(cast_label_to_float)
tokenized_dataset.set_format("torch")


# float32ë¡œ ëª…í™•íˆ Tensorí™”
def cast_label_to_float(example):
    example["labels"] = torch.tensor(example["labels"], dtype=torch.float32)
    return example


tokenized_dataset = tokenized_dataset.map(cast_label_to_float)

# âš ï¸ dtype ì—†ì´ ê·¸ëƒ¥ columnsë§Œ ì§€ì •!
tokenized_dataset.set_format(
    type="torch",
    columns=["input_ids", "attention_mask", "token_type_ids", "labels"]
)

print(tokenized_dataset["train"][0]["labels"].dtype)


# âœ… torch.float32 ì¶œë ¥ë˜ë©´ ì„±ê³µ

def predict_text(text):
    # ì…ë ¥ í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    # ëª¨ë¸ ì¶”ë¡ 
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.sigmoid(logits).cpu().numpy()[0]  # í™•ë¥  ê°’

    # ì˜ˆì¸¡ ê²°ê³¼ í•´ì„
    threshold = 0.5
    predicted = (probs >= threshold).astype(int)

    # ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
    label_columns = [
        "hate", "offensive", "gender", "age", "religion",
        "politics", "appearance", "region", "sexual_orientation"
    ]
    result = {label: float(prob) for label, prob in zip(label_columns, probs)}
    activated = [label for label, val in zip(label_columns, predicted) if val == 1]

    return result, activated


trainer.train()

sentence = "ì € ì‚¬ëŒì€ ì™œ ì €ëŸ´ê¹Œ?"
result, activated_labels = predict_text(sentence)

print("ğŸ” ì˜ˆì¸¡ í™•ë¥ :")
for label, score in result.items():
    print(f"{label:>20}: {score:.4f}")

print("\nâœ… í•´ë‹¹ ë¬¸ì¥ì—ì„œ íƒì§€ëœ ë¼ë²¨:")
print(activated_labels)

from datasets import load_dataset

ds = load_dataset("ucberkeley-dlab/measuring-hate-speech")

print(ds)
print(ds["train"][0])

from datasets import load_dataset
from transformers import (
    AutoTokenizer, ElectraForSequenceClassification,
    TrainingArguments, Trainer, EarlyStoppingCallback
)
import torch
from sklearn.metrics import accuracy_score, f1_score

# âœ… 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
dataset = load_dataset("ucberkeley-dlab/measuring-hate-speech")

target_labels = [
    'respect', 'insult', 'humiliate', 'dehumanize', 'violence',
    'genocide', 'attack_defend', 'hatespeech', 'hate_speech_score'
]


def preprocess(example):
    labels = [float(example[label]) for label in target_labels]
    return {
        "text": example["text"],
        "labels": torch.tensor(labels, dtype=torch.float)
    }


dataset = dataset["train"].map(preprocess)
dataset = dataset.train_test_split(test_size=0.2)
train_dataset = dataset["train"]
eval_dataset = dataset["test"]

# âœ… 2. í† í¬ë‚˜ì´ì§•
tokenizer = AutoTokenizer.from_pretrained("beomi/KcELECTRA-base")


def tokenize(example):
    return tokenizer(example["text"], padding="max_length", truncation=True, max_length=128)


train_dataset = train_dataset.map(tokenize, batched=True)
eval_dataset = eval_dataset.map(tokenize, batched=True)

# âœ… 3. í•™ìŠµìš© í¬ë§· ì„¤ì •
columns_to_keep = ['input_ids', 'attention_mask', 'labels']
train_dataset.set_format(type="torch", columns=columns_to_keep)
eval_dataset.set_format(type="torch", columns=columns_to_keep)

# âœ… 4. ëª¨ë¸ ì •ì˜
model = ElectraForSequenceClassification.from_pretrained(
    "beomi/KcELECTRA-base",
    num_labels=len(target_labels),
    problem_type="multi_label_classification"
)


# âœ… 5. í‰ê°€ì§€í‘œ ì •ì˜
def compute_metrics(pred):
    import numpy as np
    from sklearn.metrics import accuracy_score, f1_score

    logits, labels = pred
    probs = torch.sigmoid(torch.tensor(logits)).numpy()

    # âœ… ì´ì§„í™”ëœ ì˜ˆì¸¡ê°’
    preds = (probs >= 0.5).astype(int)

    # âœ… float -> int ë³€í™˜
    labels = np.array(labels)
    if labels.dtype != int:
        labels = (labels >= 0.5).astype(int)

    return {
        "accuracy": accuracy_score(labels, preds),
        "micro_f1": f1_score(labels, preds, average="micro", zero_division=0),
        "macro_f1": f1_score(labels, preds, average="macro", zero_division=0)
    }


# âœ… 6. í•™ìŠµ íŒŒë¼ë¯¸í„° ì •ì˜
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    logging_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=32,
    num_train_epochs=10,  # ì¶©ë¶„íˆ í° ìˆ˜ ì§€ì •
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="micro_f1",
    save_total_limit=1,
    report_to="none"
)

# âœ… 7. Trainer ì •ì˜ ë° í•™ìŠµ ì‹¤í–‰ (EarlyStopping ì¶”ê°€)
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # 2 epoch ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨
)

trainer.train()
